<!doctype html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Concept - Coalescing | Senthilkumar Gopal
</title>
  <link rel="canonical" href="https://sengopal.me/posts/concept-coalescing.html">

    <link rel="apple-touch-icon" href="https://sengopal.me/apple-touch-icon.png" sizes="180x180">
    <link rel="icon" type="image/png" href="https://sengopal.me/favicon-32x32.png" sizes="32x32">
    <link rel="icon" type="image/png" href="https://sengopal.me/favicon-16x16.png" sizes="16x16">
    <link rel="manifest" href="https://sengopal.me/manifest.json">
    <meta name="theme-color" content="#333333">

  <link rel="stylesheet" href="https://sengopal.me/theme/css/bootstrap.min.css">
  <link rel="stylesheet" href="https://sengopal.me/theme/css/all.min.css">
  <link rel="stylesheet" href="https://sengopal.me/theme/css/pygments/default.min.css">
  <link rel="stylesheet" href="https://sengopal.me/theme/css/theme.css">
  <link rel="stylesheet" href="https://sengopal.me/extras/css/skylighting-solarized-theme.css">
  <link rel="stylesheet" href="https://sengopal.me/extras/css/custom.css">

  <link rel="alternate" type="application/atom+xml" title="Full Atom Feed"
        href="https://sengopal.me/feeds/all.atom.xml">
  <link rel="alternate" type="application/atom+xml" title="Categories Atom Feed"
        href="https://sengopal.me/feeds/ml-systems.atom.xml">
<meta name="description" content="This post works through the metrics that are critical for ML inference">

<script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$', '$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
      }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>

  <script>
    (function(i, s, o, g, r, a, m) {
      i['GoogleAnalyticsObject'] = r;
      i[r] = i[r] || function() {
        (i[r].q = i[r].q || []).push(arguments)
      }, i[r].l = 1 * new Date();
      a = s.createElement(o);
      a.async = 1;
      a.src = g;
      m = s.getElementsByTagName(o)[0];
      m.parentNode.insertBefore(a, m)
    })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');
    ga('create', 'UA-67843911-1', 'auto');
    ga('send', 'pageview');
  </script>


</head>

<body>
  <header class="header">
    <div class="container">
<div class="row">
  <div class="col-sm-12">
    <h1 class="title"><a href="https://sengopal.me/">Senthilkumar Gopal</a></h1>
      <p class="text-muted">Musings of a machine learning researcher, engineer and leader</p>
      <ul class="list-inline">
            <li class="list-inline-item"><a href="https://sengopal.me/pages/about.html">About me</a></li>
            <li class="list-inline-item"><a href="https://sengopal.me/pages/publications.html">Publications</a></li>
            <li class="list-inline-item"><a href="https://sengopal.me/pages/software.html">Software</a></li>
            <li class="list-inline-item"><a href="https://sengopal.me/pages/talks.html">Talks</a></li>
            <li class=" list-inline-item text-muted">|</li>
          <li class="list-inline-item"><a class="fas fa-rss" href="https://sengopal.me/feeds/all.atom.xml" target="_blank"></a></li>
          <li class="list-inline-item"><a class="fab fa-github" href="https://github.com/sengopal" target="_blank"></a></li>
          <li class="list-inline-item"><a class="fab fa-speaker-deck" href="https://speakerdeck.com/sengopal" target="_blank"></a></li>
          <li class="list-inline-item"><a class="fab fa-google-scholar" href="https://scholar.google.com/citations?user=bs8WraEAAAAJ&hl=en" target="_blank"></a></li>
          <li class="list-inline-item"><a class="fab fa-medium" href="https://medium.com/@sengopal" target="_blank"></a></li>
          <li class="list-inline-item"><a class="fab fa-twitter" href="https://twitter.com/@sengopal" target="_blank"></a></li>
          <li class="list-inline-item"><a class="fab fa-linkedin" href="https://www.linkedin.com/in/senthilkumargopal" target="_blank"></a></li>
      </ul>
  </div>
</div>    </div>
  </header>

  <div class="main">
    <div class="container">
<article class="article">
    <header>
        <ul class="list-inline">
            <li class="list-inline-item text-muted" title="2023-12-20T00:00:00-08:00">
                <i class="fas fa-clock"></i>
                Wed 20 December 2023
            </li>
            <li class="list-inline-item">
                <i class="fas fa-folder-open"></i>
                <a href="https://sengopal.me/category/ml-systems">ML Systems</a>
            </li>
            <li class="list-inline-item">
                <i class="fas fa-tag"></i>
                <a href="https://sengopal.me/tag/ml-code">#ml-code</a>,                 <a href="https://sengopal.me/tag/llm">#llm</a>,                 <a href="https://sengopal.me/tag/ml-acceleration">#ml-acceleration</a>            </li>
        </ul>
    </header>
    <h1>Concept - Coalescing</h1>
    <div class="hidden-xs hidden-sm">
        <nav class="toc" role="doc-toc">
<ul>
<li><a href="#memory-layout-semantics-and-access-patterns" id="toc-memory-layout-semantics-and-access-patterns">Memory Layout
Semantics and Access Patterns</a>
<ul>
<li><a href="#coalesced-access-the-b-matrix" id="toc-coalesced-access-the-b-matrix">Coalesced Access – The <em>B</em>
Matrix</a></li>
<li><a href="#misaligned-access-the-a-matrix" id="toc-misaligned-access-the-a-matrix">Misaligned Access – The
<em>A</em> Matrix</a></li>
</ul></li>
<li><a href="#optimization-via-transposition" id="toc-optimization-via-transposition">Optimization via
Transposition</a>
<ul>
<li><a href="#tldr" id="toc-tldr">TLDR;</a></li>
<li><a href="#references" id="toc-references">References</a></li>
</ul></li>
</ul>
</nav>
    </div>
    <div class="content">
        <p>Memory Coalescing is a fundamental performance consideration in HPC
programming<a class="footnote-ref" href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a> and provides another dimension for
memory efficiency and how <strong>aligned versus misaligned memory
accesses</strong> can significantly impact throughput.</p>
<p>The global memory of a CUDA device is implemented with DRAMs. Each
time a DRAM location is accessed, a range of consecutive locations that
includes the requested location is actually accessed. Many sensors are
provided in each DRAM chip and they work in parallel. Each senses the
content of a bit within these consecutive locations. Once detected by
the sensors, the data from all these consecutive locations can be
transferred at very high-speed to the processor. These consecutive
locations accessed and delivered are referred to as DRAM bursts.</p>
<p>Recognizing the burst mechanism, current CUDA devices employ a
technique that allows the programmers to achieve high global memory
access efficiency by organizing memory access of threads into favorable
patterns. This technique takes advantage of the fact that threads in a
warp execute the same instruction at any given point in time (SIMT).
When all threads in a warp execute a load instruction, the hardware
detects whether they access consecutive global memory locations. If they
do, the hardware combines, or coalesces, all these accesses into a
consolidated access to consecutive DRAM locations. Such coalesced access
allows the DRAMs to deliver data as a burst.</p>
<h2 id="memory-layout-semantics-and-access-patterns">Memory Layout
Semantics and Access Patterns</h2>
<p>Programming languages provide abstract representations of matrices
and arrays, but underneath these abstractions, memory is always linear.
In C/C++ and CUDA, multidimensional arrays are typically stored in
<strong>row-major order</strong>, meaning consecutive elements of a row
occupy adjacent memory locations.</p>
<p>This becomes critically relevant in CUDA, where <strong>thread
warps</strong> execute memory accesses in parallel. When threads within
a warp access consecutive memory addresses, the hardware can
<strong>coalesce</strong> those accesses into a single wide memory
transaction. Misaligned or scattered accesses, by contrast, require
independent transactions for each thread, resulting in substantial
performance degradation.</p>
<h3 id="coalesced-access-the-b-matrix">Coalesced Access – The <em>B</em>
Matrix</h3>
<p>Consider the classic case of dense matrix multiplication<a class="footnote-ref" href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> When accessing the <em>B</em>
matrix, each CUDA thread reads a distinct column. Since matrices are
stored in row-major order, reading columns means accessing
<strong>consecutive addresses</strong> along a row — which are adjacent
in memory.</p>
<figure>
<img alt="Image ref - CoffeeBeforeArch" src="/extras/images/coalescing/coalescing-1.png"/>
<figcaption aria-hidden="true">Image ref - CoffeeBeforeArch</figcaption>
</figure>
<p><em>Image ref - CoffeeBeforeArch</em></p>
<p>This access pattern enables <strong>coalescing</strong>: instead of
multiple separate memory reads, the GPU issues a single transaction that
serves the entire warp. The result is reduced memory latency and
improved effective bandwidth.</p>
<h3 id="misaligned-access-the-a-matrix">Misaligned Access – The
<em>A</em> Matrix</h3>
<p>In contrast, accessing the <em>A</em> matrix typically involves each
thread reading a different row and iterating across columns. Due to
row-major layout, rows are <strong>not adjacent in memory</strong> —
they are separated by the width of the matrix.</p>
<figure>
<img alt="Image ref - CoffeeBeforeArch" src="/extras/images/coalescing/coalescing-2.png"/>
<figcaption aria-hidden="true">Image ref - CoffeeBeforeArch</figcaption>
</figure>
<p><em>Image ref - CoffeeBeforeArch</em></p>
<p>As a result, even if thread accesses are conceptually aligned in the
matrix, they are <strong>thousands of elements apart</strong> in memory.
These accesses are non-coalesced, forcing the hardware to issue multiple
independent transactions per warp. This behavior incurs significantly
higher latency and reduces throughput.</p>
<h2 id="optimization-via-transposition">Optimization via
Transposition</h2>
<p>To address the misaligned access pattern in the <em>A</em> matrix, a
simple yet effective transformation can be applied:
<strong>pre-transposing</strong> the <em>A</em> matrix prior to the
kernel launch. Transposition transforms rows into columns. When both A
and B matrices are accessed along columns, <strong>all memory accesses
become coalesced</strong>, optimizing memory throughput without
introducing shared memory or tiling techniques. Implementation-wise,
this requires updating index calculations inside the kernel. Rather than
iterating over fixed rows, threads iterate across columns (mirroring the
access pattern used for B)<a class="footnote-ref" href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a>.</p>
<h3 id="tldr">TLDR;</h3>
<ul>
<li><strong>Row-major layout</strong> requires careful design of access
patterns to ensure spatial locality<a class="footnote-ref" href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a>.</li>
<li>Transposing input matrices can transform misaligned accesses into
coalesced accesses.</li>
<li>Profiling should always validate performance assumptions; even minor
misalignments can incur major penalties.</li>
<li>Optimization strategies must consider not only compute efficiency
but also <strong>global memory bandwidth and access
coalescing</strong>.</li>
</ul>
<h3 id="references">References</h3>
<section class="footnotes footnotes-end-of-document" id="footnotes" role="doc-endnotes">
<hr/>
<ol>
<li id="fn1"><p><a href="https://github.com/coffeeBeforeArch">CoffeeBeforeArch</a> Github
Repository<a class="footnote-back" href="#fnref1" role="doc-backlink">↩︎</a></p></li>
<li id="fn2"><p><a href="https://www.youtube.com/watch?v=_qSP455IekE&amp;t=154s">CoffeeBeforeArch</a>
Youtube tutorial<a class="footnote-back" href="#fnref2" role="doc-backlink">↩︎</a></p></li>
<li id="fn3"><p>https://homepages.math.uic.edu/~jan/mcs572f16/mcs572notes/lec35.html<a class="footnote-back" href="#fnref3" role="doc-backlink">↩︎</a></p></li>
<li id="fn4"><p>https://medium.com/distributed-knowledge/cuda-memory-management-use-cases-f9d340f7c704<a class="footnote-back" href="#fnref4" role="doc-backlink">↩︎</a></p></li>
</ol>
</section>
    </div>
    <hr/>
    <p>If you found this useful, please cite this post using</p>
    <blockquote class="blockquote-citation">
        <p>Senthilkumar Gopal. (Dec 2023). Concept - Coalescing. sengopal.me. https://sengopal.me/posts/concept-coalescing</p>
    </blockquote>
    <p>or</p>
    <div class="citation">
        <pre class="citation">@article{gopal2023conceptcoalescing,
  title   = {Concept - Coalescing},
  author  = {Senthilkumar Gopal},
  journal = {sengopal.me},
  year    = {2023},
  month   = {Dec},
  url     = {https://sengopal.me/posts/concept-coalescing}
}</pre>
    </div>
</article>
    </div>
  </div>

  <footer class="footer">
    <div class="container">
<div class="row">
    <ul class="col-sm-6 list-inline">
        <li class="list-inline-item"><a href="https://sengopal.me/archives">Archives</a></li>
        <li class="list-inline-item"><a href="https://sengopal.me/categories">Categories</a></li>
        <li class="list-inline-item"><a href="https://sengopal.me/tags">Tags</a></li>
    </ul>
    <p class="col-sm-6 text-sm-right text-muted">
        Opinions my own. Made with &#x2764; using <a href="https://github.com/getpelican/pelican" target="_blank">Pelican</a> / <a href="https://github.com/nairobilug/pelican-alchemy" target="_blank">&#x2728;</a>        
    </p>
</div>    </div>
  </footer>

  <script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML" crossorigin="anonymous"></script>
</body>

</html>