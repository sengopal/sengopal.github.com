<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Senthilkumar Gopal - Machine Learning</title><link href="https://sengopal.me/" rel="alternate"></link><link href="https://sengopal.me/feeds/machine-learning.atom.xml" rel="self"></link><id>https://sengopal.me/</id><updated>2023-10-01T00:00:00-07:00</updated><subtitle>Musings of a machine learning researcher, engineer and leader</subtitle><entry><title>Feature data creation for Time Series</title><link href="https://sengopal.me/posts/feature-data-creation-for-time-series" rel="alternate"></link><published>2023-10-01T00:00:00-07:00</published><updated>2023-10-01T00:00:00-07:00</updated><author><name>Senthilkumar Gopal</name></author><id>tag:sengopal.me,2023-10-01:/posts/feature-data-creation-for-time-series</id><summary type="html">A quick review of feature creation for time series data.</summary><content type="html">&lt;p&gt;Timeseries data is a list of observations in a constant interval.
This post gives a quick review of how to convert the list of
observations into features and labels to build a ML model to help
predict the next observation.&lt;/p&gt;
&lt;h1 id="timeseries-feature-data-extraction"&gt;Timeseries feature data
extraction&lt;/h1&gt;
&lt;p&gt;For a time series the feature set is effectively a number of values
in the list, with the label being the next value. A range of the
observations will be used as the feature set, called the window size,
where by we would sliced a window of data and training an ML model to
predict the next observation. For a time series data of 10 observations,
we can expand the data set using windowing, where the size of the window
determines the shift by each iteration. This splits the data into
features and labels and the last item of the list being the label for
the feature. We can also shuffle and batch the data using PyTorch
DataLoader.&lt;/p&gt;
&lt;div class="sourceCode" id="cb1"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;span id="cb1-1"&gt;&lt;a aria-hidden="true" href="#cb1-1" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="im"&gt;import&lt;/span&gt; torch&lt;/span&gt;
&lt;span id="cb1-2"&gt;&lt;a aria-hidden="true" href="#cb1-2" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="im"&gt;from&lt;/span&gt; torch.utils.data &lt;span class="im"&gt;import&lt;/span&gt; TensorDataset, DataLoader&lt;/span&gt;
&lt;span id="cb1-3"&gt;&lt;a aria-hidden="true" href="#cb1-3" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-4"&gt;&lt;a aria-hidden="true" href="#cb1-4" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="co"&gt;# Generate a PyTorch tensor with numbers 0 to 9&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-5"&gt;&lt;a aria-hidden="true" href="#cb1-5" tabindex="-1"&gt;&lt;/a&gt;data &lt;span class="op"&gt;=&lt;/span&gt; torch.arange(&lt;span class="dv"&gt;10&lt;/span&gt;)&lt;/span&gt;
&lt;span id="cb1-6"&gt;&lt;a aria-hidden="true" href="#cb1-6" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-7"&gt;&lt;a aria-hidden="true" href="#cb1-7" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="co"&gt;# Define window size and shift&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-8"&gt;&lt;a aria-hidden="true" href="#cb1-8" tabindex="-1"&gt;&lt;/a&gt;window_size &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="dv"&gt;5&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-9"&gt;&lt;a aria-hidden="true" href="#cb1-9" tabindex="-1"&gt;&lt;/a&gt;shift &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-10"&gt;&lt;a aria-hidden="true" href="#cb1-10" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-11"&gt;&lt;a aria-hidden="true" href="#cb1-11" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="co"&gt;# Window the data and drop remainder&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-12"&gt;&lt;a aria-hidden="true" href="#cb1-12" tabindex="-1"&gt;&lt;/a&gt;windows &lt;span class="op"&gt;=&lt;/span&gt; [data[i:i &lt;span class="op"&gt;+&lt;/span&gt; window_size] &lt;span class="cf"&gt;for&lt;/span&gt; i &lt;span class="kw"&gt;in&lt;/span&gt; &lt;span class="bu"&gt;range&lt;/span&gt;(&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="bu"&gt;len&lt;/span&gt;(data) &lt;span class="op"&gt;-&lt;/span&gt; window_size &lt;span class="op"&gt;+&lt;/span&gt; &lt;span class="dv"&gt;1&lt;/span&gt;, shift)]&lt;/span&gt;
&lt;span id="cb1-13"&gt;&lt;a aria-hidden="true" href="#cb1-13" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-14"&gt;&lt;a aria-hidden="true" href="#cb1-14" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="co"&gt;# Flatten the windows&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-15"&gt;&lt;a aria-hidden="true" href="#cb1-15" tabindex="-1"&gt;&lt;/a&gt;flat_windows &lt;span class="op"&gt;=&lt;/span&gt; [window.flatten() &lt;span class="cf"&gt;for&lt;/span&gt; window &lt;span class="kw"&gt;in&lt;/span&gt; windows]&lt;/span&gt;
&lt;span id="cb1-16"&gt;&lt;a aria-hidden="true" href="#cb1-16" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-17"&gt;&lt;a aria-hidden="true" href="#cb1-17" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="co"&gt;# Create tuples with features (first four elements of the window) and labels (last element)&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-18"&gt;&lt;a aria-hidden="true" href="#cb1-18" tabindex="-1"&gt;&lt;/a&gt;features &lt;span class="op"&gt;=&lt;/span&gt; [window[:&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;] &lt;span class="cf"&gt;for&lt;/span&gt; window &lt;span class="kw"&gt;in&lt;/span&gt; flat_windows]&lt;/span&gt;
&lt;span id="cb1-19"&gt;&lt;a aria-hidden="true" href="#cb1-19" tabindex="-1"&gt;&lt;/a&gt;labels &lt;span class="op"&gt;=&lt;/span&gt; [window[&lt;span class="op"&gt;-&lt;/span&gt;&lt;span class="dv"&gt;1&lt;/span&gt;] &lt;span class="cf"&gt;for&lt;/span&gt; window &lt;span class="kw"&gt;in&lt;/span&gt; flat_windows]&lt;/span&gt;
&lt;span id="cb1-20"&gt;&lt;a aria-hidden="true" href="#cb1-20" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-21"&gt;&lt;a aria-hidden="true" href="#cb1-21" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="co"&gt;# Convert features and labels to PyTorch tensors&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-22"&gt;&lt;a aria-hidden="true" href="#cb1-22" tabindex="-1"&gt;&lt;/a&gt;features_tensor &lt;span class="op"&gt;=&lt;/span&gt; torch.stack(features)&lt;/span&gt;
&lt;span id="cb1-23"&gt;&lt;a aria-hidden="true" href="#cb1-23" tabindex="-1"&gt;&lt;/a&gt;labels_tensor &lt;span class="op"&gt;=&lt;/span&gt; torch.tensor(labels)&lt;/span&gt;
&lt;span id="cb1-24"&gt;&lt;a aria-hidden="true" href="#cb1-24" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-25"&gt;&lt;a aria-hidden="true" href="#cb1-25" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="co"&gt;# Create a PyTorch dataset&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-26"&gt;&lt;a aria-hidden="true" href="#cb1-26" tabindex="-1"&gt;&lt;/a&gt;dataset &lt;span class="op"&gt;=&lt;/span&gt; TensorDataset(features_tensor, labels_tensor)&lt;/span&gt;
&lt;span id="cb1-27"&gt;&lt;a aria-hidden="true" href="#cb1-27" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-28"&gt;&lt;a aria-hidden="true" href="#cb1-28" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="co"&gt;# Shuffle the dataset&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-29"&gt;&lt;a aria-hidden="true" href="#cb1-29" tabindex="-1"&gt;&lt;/a&gt;shuffle_indices &lt;span class="op"&gt;=&lt;/span&gt; torch.randperm(&lt;span class="bu"&gt;len&lt;/span&gt;(dataset))&lt;/span&gt;
&lt;span id="cb1-30"&gt;&lt;a aria-hidden="true" href="#cb1-30" tabindex="-1"&gt;&lt;/a&gt;dataset &lt;span class="op"&gt;=&lt;/span&gt; TensorDataset(features_tensor[shuffle_indices], labels_tensor[shuffle_indices])&lt;/span&gt;
&lt;span id="cb1-31"&gt;&lt;a aria-hidden="true" href="#cb1-31" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-32"&gt;&lt;a aria-hidden="true" href="#cb1-32" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="co"&gt;# Create a PyTorch DataLoader&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-33"&gt;&lt;a aria-hidden="true" href="#cb1-33" tabindex="-1"&gt;&lt;/a&gt;dataloader &lt;span class="op"&gt;=&lt;/span&gt; DataLoader(dataset, batch_size&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="dv"&gt;2&lt;/span&gt;, shuffle&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="va"&gt;True&lt;/span&gt;)&lt;/span&gt;
&lt;span id="cb1-34"&gt;&lt;a aria-hidden="true" href="#cb1-34" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-35"&gt;&lt;a aria-hidden="true" href="#cb1-35" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="co"&gt;# Print the results&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-36"&gt;&lt;a aria-hidden="true" href="#cb1-36" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="cf"&gt;for&lt;/span&gt; x, y &lt;span class="kw"&gt;in&lt;/span&gt; dataloader:&lt;/span&gt;
&lt;span id="cb1-37"&gt;&lt;a aria-hidden="true" href="#cb1-37" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;"x = "&lt;/span&gt;, x.numpy())&lt;/span&gt;
&lt;span id="cb1-38"&gt;&lt;a aria-hidden="true" href="#cb1-38" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="bu"&gt;print&lt;/span&gt;(&lt;span class="st"&gt;"y = "&lt;/span&gt;, y.numpy())&lt;/span&gt;
&lt;span id="cb1-39"&gt;&lt;a aria-hidden="true" href="#cb1-39" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="bu"&gt;print&lt;/span&gt;()&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The output for reference&lt;/p&gt;
&lt;div class="sourceCode" id="cb2"&gt;&lt;pre class="sourceCode bash"&gt;&lt;code class="sourceCode bash"&gt;&lt;span id="cb2-1"&gt;&lt;a aria-hidden="true" href="#cb2-1" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="ex"&gt;x&lt;/span&gt; =  [[5 6 7 8]&lt;/span&gt;
&lt;span id="cb2-2"&gt;&lt;a aria-hidden="true" href="#cb2-2" tabindex="-1"&gt;&lt;/a&gt; &lt;span class="ex"&gt;[0&lt;/span&gt; 1 2 3]]&lt;/span&gt;
&lt;span id="cb2-3"&gt;&lt;a aria-hidden="true" href="#cb2-3" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="ex"&gt;y&lt;/span&gt; =  [9 4]&lt;/span&gt;
&lt;span id="cb2-4"&gt;&lt;a aria-hidden="true" href="#cb2-4" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb2-5"&gt;&lt;a aria-hidden="true" href="#cb2-5" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="ex"&gt;x&lt;/span&gt; =  [[1 2 3 4]&lt;/span&gt;
&lt;span id="cb2-6"&gt;&lt;a aria-hidden="true" href="#cb2-6" tabindex="-1"&gt;&lt;/a&gt; &lt;span class="ex"&gt;[2&lt;/span&gt; 3 4 5]]&lt;/span&gt;
&lt;span id="cb2-7"&gt;&lt;a aria-hidden="true" href="#cb2-7" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="ex"&gt;y&lt;/span&gt; =  [5 6]&lt;/span&gt;
&lt;span id="cb2-8"&gt;&lt;a aria-hidden="true" href="#cb2-8" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb2-9"&gt;&lt;a aria-hidden="true" href="#cb2-9" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="ex"&gt;x&lt;/span&gt; =  [[4 5 6 7]&lt;/span&gt;
&lt;span id="cb2-10"&gt;&lt;a aria-hidden="true" href="#cb2-10" tabindex="-1"&gt;&lt;/a&gt; &lt;span class="ex"&gt;[3&lt;/span&gt; 4 5 6]]&lt;/span&gt;
&lt;span id="cb2-11"&gt;&lt;a aria-hidden="true" href="#cb2-11" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="ex"&gt;y&lt;/span&gt; =  [8 7]&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;</content><category term="Machine Learning"></category><category term="python"></category><category term="ml-code"></category><category term="pytorch"></category></entry><entry><title>ML Project Template</title><link href="https://sengopal.me/posts/ml-project-template" rel="alternate"></link><published>2023-09-23T00:00:00-07:00</published><updated>2023-09-23T00:00:00-07:00</updated><author><name>Senthilkumar Gopal</name></author><id>tag:sengopal.me,2023-09-23:/posts/ml-project-template</id><summary type="html">This post describes a typical machine learning project and ongoing documentation and tracking of its progress.</summary><content type="html">&lt;p&gt;Tracking and documenting an ongoing machine learning project is a
task onto itself. The following is a starting document of all the moving
parts involved in a machine learning project, specializing towards a
specific application such as a recommendation system or a ranking
capability etc.,. A simple forkable copy of this document is available
at https://github.com/sengopal/ml-project-template as well.&lt;/p&gt;
&lt;h1 id="project-root"&gt;Project Root&lt;/h1&gt;
&lt;p&gt;This document acts as the index README or the landing page for the
machine learning project. The intent is to capture all the necessary
decision making information and related references in one centralized
document.&lt;/p&gt;
&lt;h3 id="versions"&gt;Versions&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;&amp;lt;next version&amp;gt; - &amp;lt;what change happened and which section&amp;gt;&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;v1.0 - created on Sept 30, 2023&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id="audience"&gt;Audience&lt;/h2&gt;
&lt;p&gt;A simple list of interested folks. This section can also use RASCI
(Responsible, Accountable, Supporting, Consulted and Informed) structure
as well as necessary. This section can also include the external team
stakeholders etc.,&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="goals-and-definitions"&gt;1 Goals and Definitions&lt;/h2&gt;
&lt;p&gt;This section tracks the primary goals, vision, metrics that are being
impacted, scope and usecases.&lt;/p&gt;
&lt;h3 id="business-objectives"&gt;1.1 Business Objectives&lt;/h3&gt;
&lt;p&gt;The business objective focuses on the end customer and working
backwards from the impact expected. This section provides the need for
this project in the first place.&lt;/p&gt;
&lt;h3 id="vision"&gt;1.2 Vision&lt;/h3&gt;
&lt;p&gt;The vision explores the end vision of this experiment and can
categorize iterative improvements or vision of the project delivery.&lt;/p&gt;
&lt;h3 id="impact-metrics"&gt;1.3 Impact Metrics&lt;/h3&gt;
&lt;p&gt;These are the output business metrics that are targeted for
improvement. For a recommendation sytem this might be Null&amp;amp;Low
queries, MRR, Conversion etc., It is important to identify these
metrics, though the models may not be directly optimized only for these
metrics. &lt;em&gt;These are not the model metrics such as precision or
recall, which will be tracked in model training section.&lt;/em&gt;&lt;/p&gt;
&lt;h3 id="project-scope"&gt;1.4 Project Scope&lt;/h3&gt;
&lt;p&gt;This section defines the scope of execution impact such as
mobile/desktop, geographies planned, experiments identified, user
segments targeted etc.,&lt;/p&gt;
&lt;h3 id="usecases"&gt;1.5 Usecases&lt;/h3&gt;
&lt;p&gt;Applications and usecases identified to utilize this feature/model
and the method of consumption.&lt;/p&gt;
&lt;h3 id="opportunity-sizing-analysis"&gt;1.6 Opportunity Sizing
Analysis&lt;/h3&gt;
&lt;p&gt;This section captures the opportunity sizing for each usecase
planned. This identifies the approximate improvements in the input and
output metrics with reasonable assumptions.&lt;/p&gt;
&lt;h3 id="current-baseline"&gt;1.7 Current Baseline&lt;/h3&gt;
&lt;p&gt;This section describes the current status of the opportunity output
metrics that is being identified. These act as the baseline to measure
and experiment the model improvements and other hypothesis.&lt;/p&gt;
&lt;h3 id="data-reportingbusiness-intelligence-dashboards"&gt;1.8 Data
reporting/business intelligence dashboards&lt;/h3&gt;
&lt;p&gt;This section tracks the critical data reporting and intelligence
dashboards that this project is expected to impact. Its critical to
define the metrics and the dashboards to view the impact at the onset to
ensure consensus around clarity of project outcome.&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="data-analysis"&gt;2 Data Analysis&lt;/h2&gt;
&lt;h3 id="data-used"&gt;2.1 Data used&lt;/h3&gt;
&lt;p&gt;Location of the training/validation/test data, data freshness,
SQLs/Hadoop jobs used to create the data.&lt;/p&gt;
&lt;h3 id="data-analysis-1"&gt;2.2 Data Analysis&lt;/h3&gt;
&lt;p&gt;Exploratory analysis of the data being used - their distributions,
any missing data, biases and methods to prevent them. This section also
documents any interesting relationships observed in the data.&lt;/p&gt;
&lt;h3 id="data-loading-jobs"&gt;2.3 Data loading Jobs&lt;/h3&gt;
&lt;p&gt;ETL jobs for data loading and related transformations/conversions&lt;/p&gt;
&lt;h3 id="labeled-data-human-annotated-datasets"&gt;2.4 Labeled Data / Human
annotated datasets&lt;/h3&gt;
&lt;p&gt;Human annotated datasets that act as golden datasets for final model
performance evaluation - their exploratory analysis and locations&lt;/p&gt;
&lt;hr/&gt;
&lt;h2 id="machine-learning-model"&gt;3 Machine Learning Model&lt;/h2&gt;
&lt;p&gt;This section focuses on the machine learning part of the solution and
acts as a checkpoint journalling of models trained and its
performance.&lt;/p&gt;
&lt;h3 id="baselines-for-model-performance"&gt;3.1 Baselines for model
performance&lt;/h3&gt;
&lt;p&gt;These are the baselines established for model finetuning based on
either off the shelf model weights or any other reference models to be
used as a proxy for the downstream tasks.&lt;/p&gt;
&lt;h3 id="literature-review"&gt;3.2 Literature review&lt;/h3&gt;
&lt;p&gt;This section captures any literature review performed to determine
the variations of models to be experimented, their related notebooks
etc.,&lt;/p&gt;
&lt;h3 id="model"&gt;3.3 Model &lt;x&gt;&lt;/x&gt;&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;code&gt;&amp;lt;X&amp;gt;&lt;/code&gt; indicates the model variation tracking. These
might be either numbered or a simple identifier can be used as well.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Model architecture, pretrained weights used, finetuning dataset used
(use reference to section 1.2) 1. Find SoTA model for your problem
domain (if available) and reproduce results, then apply to your dataset
as a second baseline. 2. Track Training methods and metrics (Losses,
epochs etc.,) 3. MLflow or CometML for Training and hyperparameters
tracking 4. Model checkpoint locations 5. Model training and inference
timings 6. Hardware configuration used 7. Dependencies/Libraries -
requirements.txt or a docker image 8. Performance vs. Latency tradeoffs
9. Model export formats and comparison metrics (eg., ONNX or
TF-protobuf) 10. Training improvements (quantizations, smaller model or
dimensions) and comparison metrics&lt;/p&gt;
&lt;h3 id="model-evaluation"&gt;3.4 Model Evaluation&lt;/h3&gt;
&lt;ol type="1"&gt;
&lt;li&gt;Evaluation Metrics - training, validation and testing&lt;/li&gt;
&lt;li&gt;Experiments conducted and results&lt;/li&gt;
&lt;li&gt;Hyperparameter experiments and final parameters identified&lt;/li&gt;
&lt;li&gt;Streamlit / Gradio Demos&lt;/li&gt;
&lt;li&gt;Model Card - https://modelcards.withgoogle.com/face-detection&lt;/li&gt;
&lt;li&gt;Github location for the evaluation notebooks&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id="inference-deployments"&gt;3.5 Inference Deployments&lt;/h3&gt;
&lt;p&gt;Pytorch - code format and styleguide - ​​&lt;a class="uri" href="https://github.com/IgorSusmelj/pytorch-styleguide#recommended-code-structure-for-training-your-model"&gt;https://github.com/IgorSusmelj/pytorch-styleguide#recommended-code-structure-for-training-your-model&lt;/a&gt;&lt;/p&gt;
&lt;hr/&gt;
&lt;h3 id="ml-operations"&gt;4 ML Operations&lt;/h3&gt;
&lt;p&gt;This section documents the ML operation pipelines once the model has
been identified. There should be sub segments created for the below and
track all the information necessary as listed below.&lt;/p&gt;
&lt;ol type="1"&gt;
&lt;li&gt;Data pipeline architecture - landing page to understand the data
flow and dependencies&lt;/li&gt;
&lt;li&gt;Infrastructure diagrams
&lt;ul&gt;
&lt;li&gt;for offline batch inference - kafka topics, downstream identifiers,
capacity estimates, frequency of updates&lt;/li&gt;
&lt;li&gt;for online inference - APIs, platform used, capacity (throughput and
latency) and cluster size&lt;/li&gt;
&lt;/ul&gt;&lt;/li&gt;
&lt;li&gt;Other Integration specific system dependencies&lt;/li&gt;
&lt;li&gt;Various modes of operation and specifics - Batch (Offline), Batch
(Online), Realtime&lt;/li&gt;
&lt;li&gt;Airflow, Luigi or any other orchestration&lt;/li&gt;
&lt;li&gt;Any additional post processing - vector databases, indexing,
Quanitizations etc.,&lt;/li&gt;
&lt;li&gt;Code changes and Deployments - Source code, K8s pods&lt;/li&gt;
&lt;li&gt;Instructions for retraining, bulk inferencing etc.,&lt;/li&gt;
&lt;/ol&gt;
&lt;hr/&gt;
&lt;h3 id="project-execution-and-rollout-plan"&gt;5 Project Execution and
Rollout Plan&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Ideally this document &lt;strong&gt;should not include&lt;/strong&gt; execution
status which tracks the current status which is updated very frequently
and represents current state of affairs. there are other project
management tools to do the same.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This section tracks the intended end state of the model execution and
can also track incremental phases. Phase &lt;x&gt; - Timelines, A/B test,
dependency timelines, Github, Inference endpoints, cURL commands,
notebook links, Jenkins URL, Architecture diagrams, reference to Model
&lt;x&gt; (refer to 3.3)&lt;/x&gt;&lt;/x&gt;&lt;/p&gt;
&lt;h3 id="outcomes-and-monitoring"&gt;6 Outcomes and Monitoring&lt;/h3&gt;
&lt;p&gt;This section document the outcomes and results including the
experiments, the variants tested and observations. There should be
subsegment for results of each A/B Test variant, the impact and their
guardrail metrics. This section also should document the observations,
further model inputs and clearly indicate what is the outcome of each
experiment.&lt;/p&gt;
&lt;h3 id="monitoring"&gt;6.1 Monitoring&lt;/h3&gt;
&lt;p&gt;This section tracks the links to monitor the deployed system and data
health. 1. System Monitoring - for throughput, system health, response
time etc., 2. Data Monitoring - coverage, data drift, model metrics
etc.,&lt;/p&gt;
&lt;h3 id="playbook-for-faqs-and-commonly-known-issues"&gt;6.2 Playbook for
FAQs and commonly known issues&lt;/h3&gt;
&lt;h3 id="references"&gt;7 References&lt;/h3&gt;
&lt;p&gt;All other reference links such as 1. Internal documents 2. Refs to
wiki, screenshots, Repos with any sample code 3. External - Inspiring
work, papers for further literature review&lt;/p&gt;</content><category term="Machine Learning"></category><category term="ml-code"></category><category term="management"></category></entry><entry><title>float16 precision conversion to Base64</title><link href="https://sengopal.me/posts/float16-precision-conversion-to-base64" rel="alternate"></link><published>2023-02-20T00:00:00-08:00</published><updated>2023-02-20T00:00:00-08:00</updated><author><name>Senthilkumar Gopal</name></author><id>tag:sengopal.me,2023-02-20:/posts/float16-precision-conversion-to-base64</id><summary type="html">This post discusses the different methods in Python for converting float16 or half-precision floats to base64 and vice versa to ensure lossless transmission of numpy array data.</summary><content type="html">&lt;p&gt;With the advent of vector databases and large model based embeddings,
with dimensions of 768 and 2048, building large scale indexes for
performing ANN and storing these vectors have become expensive
operations. There are many methods of reducing the vector’s memory
footprint such as quantization or even int8. Two such well used methods
are binarization and using half-precision or float16 to store these
vectors. The following are simple code snippets that I collected from
various sources for conversion between these formats to base64 to ensure
lossless transmission over the wire, such as HTTP services.&lt;/p&gt;
&lt;h2 id="binarization"&gt;Binarization&lt;/h2&gt;
&lt;p&gt;Binarization is a simple method which works well for large
dimensional vectors. There are many methods to define the threshold such
as mean or median values per dimension etc., The below is an example of
storing a binary vector as base64 and back, packed in blocks, where each
block consists of 8 bits.&lt;/p&gt;
&lt;div class="sourceCode" id="cb1"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;span id="cb1-1"&gt;&lt;a aria-hidden="true" href="#cb1-1" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="kw"&gt;def&lt;/span&gt; base64_to_binary_vec(s):&lt;/span&gt;
&lt;span id="cb1-2"&gt;&lt;a aria-hidden="true" href="#cb1-2" tabindex="-1"&gt;&lt;/a&gt;    binary &lt;span class="op"&gt;=&lt;/span&gt; base64.b64decode(s)&lt;/span&gt;
&lt;span id="cb1-3"&gt;&lt;a aria-hidden="true" href="#cb1-3" tabindex="-1"&gt;&lt;/a&gt;    bits &lt;span class="op"&gt;=&lt;/span&gt; [&lt;span class="bu"&gt;bin&lt;/span&gt;(byte)[&lt;span class="dv"&gt;2&lt;/span&gt;:].zfill(&lt;span class="dv"&gt;8&lt;/span&gt;) &lt;span class="cf"&gt;for&lt;/span&gt; byte &lt;span class="kw"&gt;in&lt;/span&gt; binary]&lt;/span&gt;
&lt;span id="cb1-4"&gt;&lt;a aria-hidden="true" href="#cb1-4" tabindex="-1"&gt;&lt;/a&gt;    s_bits &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;''&lt;/span&gt;.join(bits)&lt;/span&gt;
&lt;span id="cb1-5"&gt;&lt;a aria-hidden="true" href="#cb1-5" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="co"&gt;# print(len(s_bits))&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-6"&gt;&lt;a aria-hidden="true" href="#cb1-6" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; s_bits&lt;/span&gt;
&lt;span id="cb1-7"&gt;&lt;a aria-hidden="true" href="#cb1-7" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-8"&gt;&lt;a aria-hidden="true" href="#cb1-8" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-9"&gt;&lt;a aria-hidden="true" href="#cb1-9" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="kw"&gt;def&lt;/span&gt; convert_binary_tob64(s_vec):&lt;/span&gt;
&lt;span id="cb1-10"&gt;&lt;a aria-hidden="true" href="#cb1-10" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; base64.b64encode(s_vec).decode(&lt;span class="st"&gt;"utf-8"&lt;/span&gt;)&lt;/span&gt;
&lt;span id="cb1-11"&gt;&lt;a aria-hidden="true" href="#cb1-11" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-12"&gt;&lt;a aria-hidden="true" href="#cb1-12" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="kw"&gt;def&lt;/span&gt; verify_binary_encoding():&lt;/span&gt;
&lt;span id="cb1-13"&gt;&lt;a aria-hidden="true" href="#cb1-13" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="co"&gt;# binary vector - example 1&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-14"&gt;&lt;a aria-hidden="true" href="#cb1-14" tabindex="-1"&gt;&lt;/a&gt;    sample_cons_str &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;"D/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A/wD/AP8A=="&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-15"&gt;&lt;a aria-hidden="true" href="#cb1-15" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="bu"&gt;print&lt;/span&gt;(base64_to_binary_vec(sample_cons_str))&lt;/span&gt;
&lt;span id="cb1-16"&gt;&lt;a aria-hidden="true" href="#cb1-16" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-17"&gt;&lt;a aria-hidden="true" href="#cb1-17" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="co"&gt;# binary vector - example 2&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-18"&gt;&lt;a aria-hidden="true" href="#cb1-18" tabindex="-1"&gt;&lt;/a&gt;    test_str &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;'vckIkrUOV/sgvGYNBfCLEimBkRMSSGxA2TESPj7ixDZNofUdJVChxmwDCSKV4TG8EYwQUhOWtRGzMjJ6LbLaVe2nCBJn3wN1LIFwA2ikTpP5DrRCBDFdVYxBkuAKARelzQRNE4QTRLm8WKbMLE1AYLgHpIy1bTtB6tGPRvU6adxDSVjDRlA9XNMlsg0NMB5tRKzLiHoUbwz8B+oNzcC/lA8I3CNyY8JD6kT1eN2Vq+Xt4eTm6AZL3/Cs9lYeG4tjjuzK0ioVMyAaStmsp2MchziKUoYShVQ2qH2HgLoRD9kJjUL7AoBzMivoZTi4jaUfVn6HooiDvAfZt8CpHqxQ0A=='&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-19"&gt;&lt;a aria-hidden="true" href="#cb1-19" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="bu"&gt;print&lt;/span&gt;(base64_to_binary_vec(test_str))&lt;/span&gt;
&lt;span id="cb1-20"&gt;&lt;a aria-hidden="true" href="#cb1-20" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-21"&gt;&lt;a aria-hidden="true" href="#cb1-21" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="co"&gt;# binary vector - example 3 - to reconstruct the vector&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-22"&gt;&lt;a aria-hidden="true" href="#cb1-22" tabindex="-1"&gt;&lt;/a&gt;    s_vec &lt;span class="op"&gt;=&lt;/span&gt; []&lt;/span&gt;
&lt;span id="cb1-23"&gt;&lt;a aria-hidden="true" href="#cb1-23" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="cf"&gt;for&lt;/span&gt; i &lt;span class="kw"&gt;in&lt;/span&gt; &lt;span class="bu"&gt;range&lt;/span&gt;(&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="dv"&gt;2048&lt;/span&gt; &lt;span class="op"&gt;//&lt;/span&gt; (&lt;span class="dv"&gt;8&lt;/span&gt; &lt;span class="op"&gt;*&lt;/span&gt; &lt;span class="dv"&gt;2&lt;/span&gt;)):&lt;/span&gt;
&lt;span id="cb1-24"&gt;&lt;a aria-hidden="true" href="#cb1-24" tabindex="-1"&gt;&lt;/a&gt;        s_vec &lt;span class="op"&gt;+=&lt;/span&gt; [&lt;span class="dv"&gt;1&lt;/span&gt;,&lt;span class="dv"&gt;1&lt;/span&gt;,&lt;span class="dv"&gt;1&lt;/span&gt;,&lt;span class="dv"&gt;1&lt;/span&gt;,&lt;span class="dv"&gt;0&lt;/span&gt;,&lt;span class="dv"&gt;0&lt;/span&gt;,&lt;span class="dv"&gt;0&lt;/span&gt;,&lt;span class="dv"&gt;0&lt;/span&gt;,&lt;span class="dv"&gt;0&lt;/span&gt;,&lt;span class="dv"&gt;0&lt;/span&gt;,&lt;span class="dv"&gt;0&lt;/span&gt;,&lt;span class="dv"&gt;0&lt;/span&gt;,&lt;span class="dv"&gt;1&lt;/span&gt;,&lt;span class="dv"&gt;1&lt;/span&gt;,&lt;span class="dv"&gt;1&lt;/span&gt;,&lt;span class="dv"&gt;1&lt;/span&gt;]&lt;/span&gt;
&lt;span id="cb1-25"&gt;&lt;a aria-hidden="true" href="#cb1-25" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-26"&gt;&lt;a aria-hidden="true" href="#cb1-26" tabindex="-1"&gt;&lt;/a&gt;    b64_str &lt;span class="op"&gt;=&lt;/span&gt; convert_binary_tob64(s_vec)&lt;/span&gt;
&lt;span id="cb1-27"&gt;&lt;a aria-hidden="true" href="#cb1-27" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="co"&gt;# print(b64_str)&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-28"&gt;&lt;a aria-hidden="true" href="#cb1-28" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="cf"&gt;assert&lt;/span&gt; (b64_str &lt;span class="op"&gt;==&lt;/span&gt; sample_cons_str)&lt;/span&gt;
&lt;span id="cb1-29"&gt;&lt;a aria-hidden="true" href="#cb1-29" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb1-30"&gt;&lt;a aria-hidden="true" href="#cb1-30" tabindex="-1"&gt;&lt;/a&gt;    s_vec_recreate &lt;span class="op"&gt;=&lt;/span&gt; base64_to_binary_vec(b64_str)&lt;/span&gt;
&lt;span id="cb1-31"&gt;&lt;a aria-hidden="true" href="#cb1-31" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="co"&gt;# print(len(s_vec_recreate))&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-32"&gt;&lt;a aria-hidden="true" href="#cb1-32" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="co"&gt;# print(s_vec_recreate)&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-33"&gt;&lt;a aria-hidden="true" href="#cb1-33" tabindex="-1"&gt;&lt;/a&gt;    s_vec_expected &lt;span class="op"&gt;=&lt;/span&gt; &lt;span class="st"&gt;''&lt;/span&gt;.join([&lt;span class="st"&gt;'0'&lt;/span&gt; &lt;span class="cf"&gt;if&lt;/span&gt; val &lt;span class="cf"&gt;else&lt;/span&gt; &lt;span class="st"&gt;'1'&lt;/span&gt; &lt;span class="cf"&gt;for&lt;/span&gt; val &lt;span class="kw"&gt;in&lt;/span&gt; s_vec])&lt;/span&gt;
&lt;span id="cb1-34"&gt;&lt;a aria-hidden="true" href="#cb1-34" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="co"&gt;# print(s_vec_expected)&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb1-35"&gt;&lt;a aria-hidden="true" href="#cb1-35" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="cf"&gt;assert&lt;/span&gt;(s_vec_recreate &lt;span class="op"&gt;==&lt;/span&gt; s_vec_expected)&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id="float-16-to-base64-conversion"&gt;Float 16 to Base64
conversion&lt;/h2&gt;
&lt;p&gt;The below is an example of storing a float 16 vector as base64 and
back to the float16 vector without any loss of data.&lt;/p&gt;
&lt;p&gt;There are multiple methods for float16 to base64 conversion.&lt;/p&gt;
&lt;h3 id="method-1---using-numpy-buffer"&gt;Method 1 - using Numpy
buffer&lt;/h3&gt;
&lt;div class="sourceCode" id="cb2"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;span id="cb2-1"&gt;&lt;a aria-hidden="true" href="#cb2-1" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="kw"&gt;def&lt;/span&gt; convert_f16_to_b64_m1(arr):&lt;/span&gt;
&lt;span id="cb2-2"&gt;&lt;a aria-hidden="true" href="#cb2-2" tabindex="-1"&gt;&lt;/a&gt;    a &lt;span class="op"&gt;=&lt;/span&gt; np.array(arr, np.float16)&lt;/span&gt;
&lt;span id="cb2-3"&gt;&lt;a aria-hidden="true" href="#cb2-3" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; base64.b64encode(a.tobytes())&lt;/span&gt;
&lt;span id="cb2-4"&gt;&lt;a aria-hidden="true" href="#cb2-4" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb2-5"&gt;&lt;a aria-hidden="true" href="#cb2-5" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="kw"&gt;def&lt;/span&gt; convert_b64_to_f16(emb):&lt;/span&gt;
&lt;span id="cb2-6"&gt;&lt;a aria-hidden="true" href="#cb2-6" tabindex="-1"&gt;&lt;/a&gt;    binary &lt;span class="op"&gt;=&lt;/span&gt; base64.b64decode(emb)&lt;/span&gt;
&lt;span id="cb2-7"&gt;&lt;a aria-hidden="true" href="#cb2-7" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="bu"&gt;print&lt;/span&gt;(binary)&lt;/span&gt;
&lt;span id="cb2-8"&gt;&lt;a aria-hidden="true" href="#cb2-8" tabindex="-1"&gt;&lt;/a&gt;    q &lt;span class="op"&gt;=&lt;/span&gt; np.frombuffer(binary, dtype&lt;span class="op"&gt;=&lt;/span&gt;np.float16)&lt;/span&gt;
&lt;span id="cb2-9"&gt;&lt;a aria-hidden="true" href="#cb2-9" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="bu"&gt;print&lt;/span&gt;(q.shape)&lt;/span&gt;
&lt;span id="cb2-10"&gt;&lt;a aria-hidden="true" href="#cb2-10" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; q&lt;/span&gt;
&lt;span id="cb2-11"&gt;&lt;a aria-hidden="true" href="#cb2-11" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb2-12"&gt;&lt;a aria-hidden="true" href="#cb2-12" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="kw"&gt;def&lt;/span&gt; verify_f16_encoding_m1():&lt;/span&gt;
&lt;span id="cb2-13"&gt;&lt;a aria-hidden="true" href="#cb2-13" tabindex="-1"&gt;&lt;/a&gt;    b64_emb &lt;span class="op"&gt;=&lt;/span&gt; convert_f16_to_b64_m1([&lt;span class="fl"&gt;1.2345&lt;/span&gt;])&lt;/span&gt;
&lt;span id="cb2-14"&gt;&lt;a aria-hidden="true" href="#cb2-14" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="cf"&gt;assert&lt;/span&gt; (np.isclose([&lt;span class="fl"&gt;1.2345&lt;/span&gt;], convert_b64_to_f16(b64_emb), atol&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;1e-2&lt;/span&gt;))&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="method-2---using-struct-pack"&gt;Method 2 - using Struct pack&lt;/h3&gt;
&lt;div class="sourceCode" id="cb3"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;span id="cb3-1"&gt;&lt;a aria-hidden="true" href="#cb3-1" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="kw"&gt;def&lt;/span&gt; convert_f16_to_b64_m2(arr):&lt;/span&gt;
&lt;span id="cb3-2"&gt;&lt;a aria-hidden="true" href="#cb3-2" tabindex="-1"&gt;&lt;/a&gt;    packer &lt;span class="op"&gt;=&lt;/span&gt; struct.Struct(&lt;span class="st"&gt;"&amp;lt;96e"&lt;/span&gt;)&lt;/span&gt;
&lt;span id="cb3-3"&gt;&lt;a aria-hidden="true" href="#cb3-3" tabindex="-1"&gt;&lt;/a&gt;    vector_array &lt;span class="op"&gt;=&lt;/span&gt; np.array(arr, dtype&lt;span class="op"&gt;=&lt;/span&gt;np.float16).tolist()&lt;/span&gt;
&lt;span id="cb3-4"&gt;&lt;a aria-hidden="true" href="#cb3-4" tabindex="-1"&gt;&lt;/a&gt;    vector_bytes &lt;span class="op"&gt;=&lt;/span&gt; packer.pack(&lt;span class="op"&gt;*&lt;/span&gt;vector_array)&lt;/span&gt;
&lt;span id="cb3-5"&gt;&lt;a aria-hidden="true" href="#cb3-5" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; base64.b64encode(vector_bytes)&lt;/span&gt;
&lt;span id="cb3-6"&gt;&lt;a aria-hidden="true" href="#cb3-6" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb3-7"&gt;&lt;a aria-hidden="true" href="#cb3-7" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="kw"&gt;def&lt;/span&gt; verify_f16_encoding_m2():&lt;/span&gt;
&lt;span id="cb3-8"&gt;&lt;a aria-hidden="true" href="#cb3-8" tabindex="-1"&gt;&lt;/a&gt;    arr &lt;span class="op"&gt;=&lt;/span&gt; np.random.normal(&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="fl"&gt;0.01&lt;/span&gt;, &lt;span class="dv"&gt;96&lt;/span&gt;).astype(&lt;span class="st"&gt;'float16'&lt;/span&gt;)&lt;/span&gt;
&lt;span id="cb3-9"&gt;&lt;a aria-hidden="true" href="#cb3-9" tabindex="-1"&gt;&lt;/a&gt;    b64_emb &lt;span class="op"&gt;=&lt;/span&gt; convert_f16_to_b64_m2(&lt;span class="bu"&gt;list&lt;/span&gt;(arr))&lt;/span&gt;
&lt;span id="cb3-10"&gt;&lt;a aria-hidden="true" href="#cb3-10" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="cf"&gt;assert&lt;/span&gt;(np.isclose(arr, convert_b64_to_f16(b64_emb), atol&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;1e-2&lt;/span&gt;).&lt;span class="bu"&gt;all&lt;/span&gt;())&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="method-3---using-dtype-indicator"&gt;Method 3 - using dtype
indicator&lt;/h3&gt;
&lt;p&gt;Based on the method described at &lt;a href="https://numpy.org/doc/stable/reference/arrays.dtypes.html"&gt;arrays.dtypes.html&lt;/a&gt;,
&lt;code&gt;&amp;lt;f2&lt;/code&gt; is supposed to be faster than struct.&lt;/p&gt;
&lt;div class="sourceCode" id="cb4"&gt;&lt;pre class="sourceCode python"&gt;&lt;code class="sourceCode python"&gt;&lt;span id="cb4-1"&gt;&lt;a aria-hidden="true" href="#cb4-1" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="kw"&gt;def&lt;/span&gt; convert_f16_to_b64_m3(arr):&lt;/span&gt;
&lt;span id="cb4-2"&gt;&lt;a aria-hidden="true" href="#cb4-2" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="co"&gt;# using f2 is faster&lt;/span&gt;&lt;/span&gt;
&lt;span id="cb4-3"&gt;&lt;a aria-hidden="true" href="#cb4-3" tabindex="-1"&gt;&lt;/a&gt;    a &lt;span class="op"&gt;=&lt;/span&gt; np.array(arr, dtype&lt;span class="op"&gt;=&lt;/span&gt;np.dtype(&lt;span class="st"&gt;'&amp;lt;f2'&lt;/span&gt;))&lt;/span&gt;
&lt;span id="cb4-4"&gt;&lt;a aria-hidden="true" href="#cb4-4" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="cf"&gt;return&lt;/span&gt; base64.b64encode(a.tobytes())&lt;/span&gt;
&lt;span id="cb4-5"&gt;&lt;a aria-hidden="true" href="#cb4-5" tabindex="-1"&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id="cb4-6"&gt;&lt;a aria-hidden="true" href="#cb4-6" tabindex="-1"&gt;&lt;/a&gt;&lt;span class="kw"&gt;def&lt;/span&gt; verify_f16_encoding_m3():&lt;/span&gt;
&lt;span id="cb4-7"&gt;&lt;a aria-hidden="true" href="#cb4-7" tabindex="-1"&gt;&lt;/a&gt;    arr &lt;span class="op"&gt;=&lt;/span&gt; np.random.normal(&lt;span class="dv"&gt;0&lt;/span&gt;, &lt;span class="fl"&gt;0.01&lt;/span&gt;, &lt;span class="dv"&gt;96&lt;/span&gt;).astype(&lt;span class="st"&gt;'float16'&lt;/span&gt;)&lt;/span&gt;
&lt;span id="cb4-8"&gt;&lt;a aria-hidden="true" href="#cb4-8" tabindex="-1"&gt;&lt;/a&gt;    b64_emb &lt;span class="op"&gt;=&lt;/span&gt; convert_f16_to_b64_m3(&lt;span class="bu"&gt;list&lt;/span&gt;(arr))&lt;/span&gt;
&lt;span id="cb4-9"&gt;&lt;a aria-hidden="true" href="#cb4-9" tabindex="-1"&gt;&lt;/a&gt;    &lt;span class="cf"&gt;assert&lt;/span&gt;(np.isclose(arr, convert_b64_to_f16(b64_emb), atol&lt;span class="op"&gt;=&lt;/span&gt;&lt;span class="fl"&gt;1e-5&lt;/span&gt;).&lt;span class="bu"&gt;all&lt;/span&gt;())&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id="conclusion"&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;The same can be achieved using &lt;a href="https://stackoverflow.com/questions/6162651/half-precision-floating-point-in-java"&gt;Java/Scala&lt;/a&gt;
as well.&lt;/p&gt;</content><category term="Machine Learning"></category><category term="backend"></category><category term="services"></category><category term="python"></category><category term="ml-code"></category></entry></feed>